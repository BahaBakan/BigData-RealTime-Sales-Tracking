# ğŸš€ GerÃ§ek ZamanlÄ± SatÄ±ÅŸ ve Stok Takip Sistemi (Big Data Pipeline)

Bu proje, modern e-ticaret sistemlerinde karÅŸÄ±laÅŸÄ±lan bÃ¼yÃ¼k veri yÃ¶netimi sorunlarÄ±na Ã§Ã¶zÃ¼m Ã¼retmek amacÄ±yla geliÅŸtirilmiÅŸ Ã¶lÃ§eklenebilir bir veri boru hattÄ± (pipeline) Ã§alÄ±ÅŸmasÄ±dÄ±r. Proje kapsamÄ±nda 2 milyon satÄ±rlÄ±k veri iÅŸlenmiÅŸ, versiyonlanmÄ±ÅŸ ve bulut ortamÄ±na taÅŸÄ±narak gÃ¶rselleÅŸtirilmiÅŸtir.

## ğŸ“‹ Proje Ã–zeti

Bu projede Python kullanÄ±larak sentetik olarak Ã¼retilen satÄ±ÅŸ ve stok verileri, bellek darboÄŸazÄ± yaÅŸanmadan **Apache Dask** ile iÅŸlenmiÅŸ, **Apache Iceberg** ile veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ ve versiyon kontrolÃ¼ (Time Travel) saÄŸlanmÄ±ÅŸ, son olarak **Snowflake** bulut veri ambarÄ±na aktarÄ±larak **Power BI** Ã¼zerinden analiz edilmiÅŸtir.

### ğŸ¯ Temel AmaÃ§lar
* **Ã–lÃ§eklenebilirlik:** BÃ¼yÃ¼k veri setlerinin (2M+ satÄ±r) bellek darboÄŸazÄ± olmadan iÅŸlenmesi.
* **Veri BÃ¼tÃ¼nlÃ¼ÄŸÃ¼:** Apache Iceberg kullanÄ±larak ACID transaction ve Time Travel Ã¶zelliklerinin uygulanmasÄ±.
* **Bulut Entegrasyonu:** Yerel ortamda iÅŸlenen verilerin Snowflake Cloud Data Warehouse'a aktarÄ±lmasÄ±.
* **Ä°ÅŸ ZekasÄ±:** Elde edilen sonuÃ§larÄ±n karar destek mekanizmalarÄ± iÃ§in gÃ¶rselleÅŸtirilmesi.

---

## ğŸ› ï¸ KullanÄ±lan Teknolojiler (Tech Stack)

Projede aÅŸaÄŸÄ±daki teknoloji yÄ±ÄŸÄ±nÄ± kullanÄ±lmÄ±ÅŸtÄ±r:

* **Veri Ãœretimi (Simulation):** Python (Faker, NumPy) - Parquet formatÄ±nda bÃ¶lÃ¼mlenmiÅŸ veri Ã¼retimi.
* **ETL (Extract, Transform, Load):** Apache Dask - "Lazy Evaluation" ile daÄŸÄ±tÄ±k veri iÅŸleme ve temizleme.
* **Data Lake (Veri GÃ¶lÃ¼):** Apache Iceberg - Veri versiyonlama, ÅŸema yÃ¶netimi ve zaman yolculuÄŸu (Time Travel).
* **Data Warehouse (Veri AmbarÄ±):** Snowflake - Bulut tabanlÄ± veri depolama (Internal Stage & Bulk Load).
* **GÃ¶rselleÅŸtirme (BI):** Power BI - CanlÄ± veri baÄŸlantÄ±sÄ± ve dashboard tasarÄ±mÄ±.

---

## âš™ï¸ Sistem Mimarisi

Veri akÄ±ÅŸÄ± ÅŸu adÄ±mlardan oluÅŸmaktadÄ±r:
1.  **SimÃ¼lasyon:** SatÄ±ÅŸ ve stok verilerinin Ã¼retilmesi (Ä°stanbul ve Ankara aÄŸÄ±rlÄ±klÄ± daÄŸÄ±lÄ±m).
2.  **ETL:** Eksik verilerin (NaN) doldurulmasÄ±, tip dÃ¶nÃ¼ÅŸÃ¼mleri ve bÃ¶lgesel ciro hesaplamalarÄ±.
3.  **Data Lake:** Verinin Iceberg tablolarÄ±na yazÄ±lmasÄ± ve geÃ§miÅŸ versiyon sorgularÄ±nÄ±n test edilmesi.
4.  **Warehouse:** Ä°ÅŸlenmiÅŸ verinin Snowflake'e aktarÄ±lmasÄ±.
5.  **Dashboard:** SonuÃ§larÄ±n raporlanmasÄ±.

---

## ğŸš€ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

Projeyi yerel ortamÄ±nÄ±zda Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyebilirsiniz:

### 1. Gereksinimler
Proje Python tabanlÄ±dÄ±r. Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:
```bash
pip install -r requirements.txt
